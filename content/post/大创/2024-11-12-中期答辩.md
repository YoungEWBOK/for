---
title: 中期答辩
date: '2024-11-12'
summary: 准备得不太充分，上台讲得磕磕绊绊，但是中期答辩有点随意，老师让我继续好好做。
tags:
  - 答辩
share: false
---

## **内容**

各位老师好，我中期答辩的项目是“基于具身对话的多模态融合研究”，在本项目中，我聚焦的是空中视觉对话导航这一任务。

**(翻页)**

接下来我将从以下四个方面来进行汇报。(选题背景、研究方法、研究进展、后续规划)

**(翻页)**

首先是选题背景。

**(翻页)**

我们的项目主要是为了使无人机能够基于语言指令和视觉信息，成功实现自主导航，从而为救援和物流等任务提供更加智能化的方案。

接下来我介绍一下空中视觉对话导航这个任务：无人机根据对话历史和视野区域内的图像，预测空中导航动作，引导其到达目标区域 {{< math >}}$G${{< /math >}} 

具体来说，无人机需要在导航时间步 {{< math >}}$T_i${{< /math >}} 和 {{< math >}}$T_{i+1}${{< /math >}} 之间预测一个动作 {{< math >}}$\hat a_j${{< /math >}} ，输入包括了从导航开始到当前时间步的历史对话以及相应视野区域的图像。执行完动作 {{< math >}}$\hat a_j${{< /math >}} 后，随之生成一个新的视野区域的图像 {{< math >}}$\hat u_j${{< /math >}} 。

评估导航是否到达的标准是：无人机的中心是否处于目标区域 {{< math >}}$G${{< /math >}} 的范围中，并且和目标范围的交并比超过0.4。

**(翻页)**

接下来我来介绍一下我在本项目中的研究方法。

以下是我的研究方案，我结合着模型架构来进行介绍。

**(翻页)**

首先，我使用DeBERTa编码器，生成对话历史的语言嵌入，利用全连接方向编码器生成方向嵌入，我利用遥感数据集预训练了以Vision-Transformer为主干网络的CLIP模型，同时结合注意力模块提取并扁平化视觉特征；接着，动态生成三角函数式位置编码，添加到语言特征、帧特征、方向特征中，将所有的嵌入串联，输入到多模态的Transformer中，我利用交叉注意力模块关联不同模态的特征，生成多模态嵌入；最后，多模态嵌入经过全连接层获得最终输出，最终输出包含预测的三维坐标 {{< math >}}$w${{< /math >}} 和导航进度  {{< math >}}$g${{< /math >}}  ，通过当前点和预测的坐标，无人机就能够获得预测方向以及旋转角度等信息。

**(翻页)**

同时，为了增强模型的泛化能力，我做了数据增强。我利用大模型对训练数据进行了同义转写，把相同的语义不同的表述方式表达出来。

针对数据集是来自卫星图像，我使用了适合航拍场景的数据增强策略，从而适应天气变化、不同光照条件和相机抖动等情况。

**(翻页)**

截至目前，我的研究获得了以下进展。

**(翻页)**

针对成功率、加权成功率、目标进度等指标，我的模型比基线模型都展现出了更加优秀的效果。

**(翻页)**

从几个可视化的结果来分析：绿色轨迹是在当前时间步的真实方向，洋红色轨迹则是预测方向。可以看到基线模型的轨迹与真实方向的偏离程度较大，且距离目标区域的位置更远，而我们的模型则更贴合实际方向；这张图的结果也是一样，我们的模型在更短的时间步内成功到达了目标区域，而基线模型则始终在目标区域周围打转。

由此可以证明我们模型的有效性。

**(翻页)**

最后是我的后续规划。

通过分析实验结果中一些存在问题的样例，我发现仍然存在一些预测轨迹和真实轨迹夹角较大的情况。所以针对这些问题，我规划改良导航算法，引入新的模块解决这一问题；同时，我也在探索结合大语言模型辅助导航的可能，为无人机提供更细粒度的指引。

**(翻页)**

我计划引入一种基于图结构的视觉感知方法，通过将环境中的视觉信息编码为图结构，模型可以在导航过程中更好地进行路径优化和动态规划，增强模型在空间理解、路径规划方面的能力。

**(翻页)**

以上就是我的汇报内容，恳请各位老师批评指正。

**问：为什么不使用GPS进行导航定位？**

GPS信号在复杂的城市环境中，容易受到干扰，影响定位精度。